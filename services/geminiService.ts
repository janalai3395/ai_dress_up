
import { GoogleGenAI, Modality } from "@google/genai";
import type { FileData } from '../types';

const API_KEY = process.env.API_KEY;

if (!API_KEY) {
  throw new Error("API_KEY environment variable is not set.");
}

const ai = new GoogleGenAI({ apiKey: API_KEY });

/**
 * Calls the Gemini API to perform a virtual try-on.
 * @param person The person's image data.
 * @param clothing The clothing item's image data.
 * @returns A promise that resolves to the base64 string of the generated image.
 */
export const performVirtualTryOn = async (person: FileData, clothing: FileData): Promise<string> => {
  const model = 'gemini-2.5-flash-image';
  
  const personImagePart = {
    inlineData: {
      data: person.base64,
      mimeType: person.mimeType,
    },
  };

  const clothingImagePart = {
    inlineData: {
      data: clothing.base64,
      mimeType: clothing.mimeType,
    },
  };

  // A clear, directive prompt for the model.
  const textPart = {
    text: "Take the clothing from the second image and place it realistically on the person in the first image. The final image should only show the person wearing the clothes, maintaining the original background and the person's pose.",
  };

  try {
    const response = await ai.models.generateContent({
      model,
      contents: {
        parts: [personImagePart, clothingImagePart, textPart],
      },
      config: {
        responseModalities: [Modality.IMAGE],
      },
    });

    // Find the image part in the response
    for (const part of response.candidates[0].content.parts) {
      if (part.inlineData) {
        return part.inlineData.data;
      }
    }
    
    throw new Error("No image was generated by the model.");

  } catch (error) {
    console.error("Error calling Gemini API:", error);
    throw new Error("The AI model could not process the request.");
  }
};
